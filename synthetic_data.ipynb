{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get the background and distraction/cofounding elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pMXT5UPL3vd",
    "outputId": "77711421-c299-4d99-8a82-fbe80ac7276e"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# wget the background images from http://graphics.cs.cmu.edu/projects/whatMakesParis/\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# Directory to save the .jpg files\n",
    "directory=\"backgrounds\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "mkdir -p \"$directory\"\n",
    "\n",
    "# Loop through numbers 1 to 100\n",
    "for i in {1..100}\n",
    "do\n",
    "  # Construct the URL for the current file\n",
    "  url=\"http://graphics.cs.cmu.edu/projects/whatMakesParis/testimgs/${i}.jpg\"\n",
    "\n",
    "  # Download the file to the specified directory\n",
    "  wget \"$url\" -P \"$directory\"\n",
    "\n",
    "  echo \"Downloaded ${i}.jpg\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfkigUkRVldT",
    "outputId": "869a77f6-afd6-4756-d081-9494e5268216"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# wget distractions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "mkdir -p \"distractions\"\n",
    "\n",
    "# download the lamps\n",
    "for i in $(seq 14075 14094); do\n",
    "  wget \"http://graphics.cs.cmu.edu/projects/whatMakesParis/result/alldiscpatchimg[]/$i.jpg\" -P distractions\n",
    "done\n",
    "\n",
    "# download the wall\n",
    "for i in $(seq 13915 13934); do\n",
    "  wget \"http://graphics.cs.cmu.edu/projects/whatMakesParis/result/alldiscpatchimg[]/$i.jpg\" -P distractions\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download and Process the drone images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65Rh8sePNt1u",
    "outputId": "84072d8a-ef23-4203-d887-4293ee005c61"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# wget images from https://freepngimg.com/electronics/drone into drones directory\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "mkdir -p \"drones\"\n",
    "\n",
    "# download images\n",
    "wget https://freepngimg.com/download/drone/21576-6-drone-image.png -P drones\n",
    "wget https://freepngimg.com/download/drone/21682-6-drone-picture.png -P drones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJ3O7Rb5MWEU",
    "outputId": "0a741710-fdea-4ae1-cce8-55b53ffcc97a"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# There are some images in drones directory. However, some of the images have transparent pixels around them, \n",
    "# instead of the border of iamge is fit to the object itself. Please remove these pixels. Then save as png file\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def remove_transparent_pixels(image_path, output_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not open or read image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    if img.shape[2] == 4:  # Check if the image has an alpha channel\n",
    "        # Find the bounding box of non-transparent pixels\n",
    "        alpha = img[:, :, 3]\n",
    "        rows = np.any(alpha, axis=1)\n",
    "        cols = np.any(alpha, axis=0)\n",
    "        rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "        cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "        # Crop the image to the bounding box\n",
    "        img = img[rmin:rmax+1, cmin:cmax+1, :]\n",
    "\n",
    "    # Save as PNG\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "\n",
    "# Iterate through the images in the 'drones' directory\n",
    "drones_dir = \"drones\"\n",
    "output_dir = \"drones_processed\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for filename in os.listdir(drones_dir):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(drones_dir, filename)\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \".png\")\n",
    "        remove_transparent_pixels(image_path, output_path)\n",
    "        print(f\"Processed: {filename}, saved as: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUUETgyK8Ps1",
    "outputId": "0beb99c0-8474-4d1f-c03d-2a003580d8c8"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Create the synthetic dataset\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# --- Configuration ---\n",
    "background_dir = 'backgrounds'\n",
    "drone_dir = 'drones_processed'\n",
    "distraction_dir = 'distractions'\n",
    "output_dir = 'synthetic'\n",
    "output_images_dir = os.path.join(output_dir, 'images')\n",
    "output_labels_dir = os.path.join(output_dir, 'labels')\n",
    "\n",
    "# Number of drones to insert per background image copy\n",
    "N = 3  # Change as needed\n",
    "\n",
    "# Number of copies to create per background image\n",
    "M = 20  # Change as needed\n",
    "\n",
    "# Number of distractions to insert per background image copy\n",
    "K = 3  # Change as needed\n",
    "\n",
    "# Target height for the background images\n",
    "target_bg_height = 960\n",
    "\n",
    "# Create output directories if they do not exist\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Function to get image paths from a directory\n",
    "def get_image_paths(directory):\n",
    "    valid_exts = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "            if f.lower().endswith(valid_exts)]\n",
    "\n",
    "background_paths = get_image_paths(background_dir)\n",
    "drone_paths = get_image_paths(drone_dir)\n",
    "distraction_paths = get_image_paths(distraction_dir)\n",
    "\n",
    "# Function to rotate an image (with possible alpha channel)\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M_rot = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    # Compute new bounding dimensions\n",
    "    cos = np.abs(M_rot[0, 0])\n",
    "    sin = np.abs(M_rot[0, 1])\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "    # Adjust the rotation matrix to take into account translation\n",
    "    M_rot[0, 2] += (new_w / 2) - center[0]\n",
    "    M_rot[1, 2] += (new_h / 2) - center[1]\n",
    "    rotated = cv2.warpAffine(image, M_rot, (new_w, new_h), flags=cv2.INTER_LINEAR,\n",
    "                             borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))\n",
    "    return rotated\n",
    "\n",
    "# Process each background image\n",
    "for bg_path in background_paths:\n",
    "    bg_orig = cv2.imread(bg_path)\n",
    "    if bg_orig is None:\n",
    "        continue  # Skip if unable to load image\n",
    "\n",
    "    # Rescale the background image so that its height is target_bg_height while keeping the aspect ratio\n",
    "    orig_H, orig_W = bg_orig.shape[:2]\n",
    "    scale_factor = target_bg_height / orig_H\n",
    "    new_W = int(orig_W * scale_factor)\n",
    "    bg_orig = cv2.resize(bg_orig, (new_W, target_bg_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(bg_path))[0]\n",
    "\n",
    "    # Create M copies for each background image\n",
    "    for m in range(M):\n",
    "        bg = bg_orig.copy()\n",
    "        H, W = bg.shape[:2]\n",
    "        annotations = []  # To store YOLOv8 annotations for drones only\n",
    "\n",
    "        # Insert K distraction images (not annotated)\n",
    "        for i in range(K):\n",
    "            distraction_path = random.choice(distraction_paths)\n",
    "            distraction = cv2.imread(distraction_path, cv2.IMREAD_UNCHANGED)\n",
    "            if distraction is None:\n",
    "                continue\n",
    "\n",
    "            # Set target height between 100 and 200 pixels for distraction\n",
    "            target_height = random.randint(100, 200)\n",
    "            scale = target_height / distraction.shape[0]\n",
    "            new_width = int(distraction.shape[1] * scale)\n",
    "            new_height = int(distraction.shape[0] * scale)\n",
    "            distraction = cv2.resize(distraction, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Apply a random rotation between -3 and 3 degrees.\n",
    "            angle = random.uniform(-3, 3)\n",
    "            distraction = rotate_image(distraction, angle)\n",
    "            d_h, d_w = distraction.shape[:2]\n",
    "\n",
    "            # If the distraction is larger than the background, scale it down further.\n",
    "            if d_w >= W or d_h >= H:\n",
    "                factor = min(W / d_w, H / d_h) * 0.9\n",
    "                distraction = cv2.resize(distraction, (int(d_w * factor), int(d_h * factor)), interpolation=cv2.INTER_AREA)\n",
    "                d_h, d_w = distraction.shape[:2]\n",
    "\n",
    "            # Choose a random location where the distraction fully fits within the background.\n",
    "            max_x = W - d_w\n",
    "            max_y = H - d_h\n",
    "            if max_x <= 0 or max_y <= 0:\n",
    "                continue  # Skip if the distraction cannot be placed properly\n",
    "            x_offset = random.randint(0, max_x)\n",
    "            y_offset = random.randint(0, max_y)\n",
    "\n",
    "            # Paste the distraction onto the background.\n",
    "            if distraction.shape[2] == 4:\n",
    "                overlay_rgb = distraction[:, :, :3]\n",
    "                alpha_mask = distraction[:, :, 3] / 255.0\n",
    "                roi = bg[y_offset:y_offset+d_h, x_offset:x_offset+d_w]\n",
    "                for c in range(3):\n",
    "                    roi[:, :, c] = (roi[:, :, c] * (1 - alpha_mask) +\n",
    "                                    overlay_rgb[:, :, c] * alpha_mask)\n",
    "                bg[y_offset:y_offset+d_h, x_offset:x_offset+d_w] = roi\n",
    "            else:\n",
    "                bg[y_offset:y_offset+d_h, x_offset:x_offset+d_w] = distraction\n",
    "\n",
    "        # Insert N drone images (annotated)\n",
    "        for i in range(N):\n",
    "            drone_path = random.choice(drone_paths)\n",
    "            drone = cv2.imread(drone_path, cv2.IMREAD_UNCHANGED)\n",
    "            if drone is None:\n",
    "                continue\n",
    "\n",
    "            # Set the drone's target height to a random value between 40 and 70 pixels.\n",
    "            target_height = random.randint(40, 70)\n",
    "            scale = target_height / drone.shape[0]\n",
    "            new_width = int(drone.shape[1] * scale)\n",
    "            new_height = int(drone.shape[0] * scale)\n",
    "            drone = cv2.resize(drone, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Apply a random rotation between -3 and 3 degrees.\n",
    "            angle = random.uniform(-3, 3)\n",
    "            drone = rotate_image(drone, angle)\n",
    "            drone_h, drone_w = drone.shape[:2]\n",
    "\n",
    "            # If the drone image is larger than the background, scale it down further.\n",
    "            if drone_w >= W or drone_h >= H:\n",
    "                factor = min(W / drone_w, H / drone_h) * 0.9\n",
    "                drone = cv2.resize(drone, (int(drone_w * factor), int(drone_h * factor)), interpolation=cv2.INTER_AREA)\n",
    "                drone_h, drone_w = drone.shape[:2]\n",
    "\n",
    "            # Choose a random location where the drone fully fits within the background.\n",
    "            max_x = W - drone_w\n",
    "            max_y = H - drone_h\n",
    "            if max_x <= 0 or max_y <= 0:\n",
    "                continue  # Skip if the drone cannot be placed properly\n",
    "            x_offset = random.randint(0, max_x)\n",
    "            y_offset = random.randint(0, max_y)\n",
    "\n",
    "            # Paste the drone onto the background.\n",
    "            if drone.shape[2] == 4:\n",
    "                overlay_rgb = drone[:, :, :3]\n",
    "                alpha_mask = drone[:, :, 3] / 255.0\n",
    "                roi = bg[y_offset:y_offset+drone_h, x_offset:x_offset+drone_w]\n",
    "                for c in range(3):\n",
    "                    roi[:, :, c] = (roi[:, :, c] * (1 - alpha_mask) +\n",
    "                                    overlay_rgb[:, :, c] * alpha_mask)\n",
    "                bg[y_offset:y_offset+drone_h, x_offset:x_offset+drone_w] = roi\n",
    "            else:\n",
    "                bg[y_offset:y_offset+drone_h, x_offset:x_offset+drone_w] = drone\n",
    "\n",
    "            # Compute YOLOv8 annotation (format: class_id x_center y_center width height normalized).\n",
    "            x_center = (x_offset + drone_w / 2) / W\n",
    "            y_center = (y_offset + drone_h / 2) / H\n",
    "            width_norm = drone_w / W\n",
    "            height_norm = drone_h / H\n",
    "            annotations.append(f\"0 {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\")\n",
    "\n",
    "        # Save the new image and its corresponding YOLO annotation text file.\n",
    "        output_img_path = os.path.join(output_images_dir, f\"{base_name}_{m}.jpg\")\n",
    "        output_txt_path = os.path.join(output_labels_dir, f\"{base_name}_{m}.txt\")\n",
    "        cv2.imwrite(output_img_path, bg)\n",
    "        with open(output_txt_path, 'w') as f:\n",
    "            for ann in annotations:\n",
    "                f.write(ann + '\\n')\n",
    "\n",
    "print(\"Dataset generation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome To Colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
